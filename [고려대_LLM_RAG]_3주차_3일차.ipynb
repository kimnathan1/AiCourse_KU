{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWn1eQfeQREv"
      },
      "outputs": [],
      "source": [
        "!pip install langchain langchain-core langchain-openai openai --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_openai  import ChatOpenAI\n",
        "from langchain.schema  import StrOutputParser"
      ],
      "metadata": {
        "id": "GkXdUIvvjYem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ],
      "metadata": {
        "id": "-_lwYcgkkiou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 프롬프트, LLM 모델, 출력 파서\n",
        "prompt = ChatPromptTemplate.from_template(\"'{topic}'을 한 문장으로 요약해줘\")\n",
        "llm    = ChatOpenAI(model = 'gpt-4o-mini')\n",
        "parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "8aC9rpG2j-Y1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | llm | parser\n",
        "result = chain.invoke({\"topic\" : \"딥러닝이란 무엇인가?\"})"
      ],
      "metadata": {
        "id": "a40dgIoWk_Dg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHQkcjqmkM2Z",
        "outputId": "9757e0e8-c983-4435-a0c5-1076d2892733"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "딥러닝이란 인공신경망을 기반으로 데이터를 분석하고 학습하여 다양한 문제를 해결하는 머신러닝의 한 분야이다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# stream에 대한 실행\n",
        "\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "\n",
        "llm_stream = ChatOpenAI(\n",
        "    model='gpt-4o-mini',\n",
        "    streaming = True, # 실시간 타자치는 효과\n",
        "    callbacks=[StreamingStdOutCallbackHandler()] # 출력에 대한 담당자를 호출\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(\"'{topic}'을 초등학생도 이해할 수 있게 설명해줘\")\n",
        "\n",
        "chain_stream = prompt | llm_stream\n",
        "\n",
        "chain_stream.invoke({'topic': '인공지능'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pb7krAt0mPE_",
        "outputId": "f61da9a2-ed74-435b-e6f2-4d658ea81f21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인공지능은 컴퓨터나 기계가 사람들이 하는 일을 비슷하게 하는 능력을 말해. 예를 들어, 우리가 문제를 풀거나 과제를 할 때 생각하고 판단하는 것처럼, 인공지능도 정보를 바탕으로 결정을 내릴 수 있어.\n",
            "\n",
            "마치 사람처럼 생각한다고 생각할 수 있지만, 사실은 아주 많은 데이터를 빠르게 처리해서 패턴을 찾아내고, 그에 맞는 행동을 하는 거야. 예를 들어, 스마트폰에서 애완동물 사진을 찾아주거나, 게임에서 적을 피하는 방법을 알려주는 것도 인공지능이야.\n",
            "\n",
            "아주 똑똑한 로봇이나 프로그램처럼 생각하면 돼. 하지만 인공지능은 우리처럼 감정을 느끼거나 스스로 생각하지는 못해. 그 대신 사람들이 입력한 정보를 바탕으로 일을 하게 되는 거지."
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='인공지능은 컴퓨터나 기계가 사람들이 하는 일을 비슷하게 하는 능력을 말해. 예를 들어, 우리가 문제를 풀거나 과제를 할 때 생각하고 판단하는 것처럼, 인공지능도 정보를 바탕으로 결정을 내릴 수 있어.\\n\\n마치 사람처럼 생각한다고 생각할 수 있지만, 사실은 아주 많은 데이터를 빠르게 처리해서 패턴을 찾아내고, 그에 맞는 행동을 하는 거야. 예를 들어, 스마트폰에서 애완동물 사진을 찾아주거나, 게임에서 적을 피하는 방법을 알려주는 것도 인공지능이야.\\n\\n아주 똑똑한 로봇이나 프로그램처럼 생각하면 돼. 하지만 인공지능은 우리처럼 감정을 느끼거나 스스로 생각하지는 못해. 그 대신 사람들이 입력한 정보를 바탕으로 일을 하게 되는 거지.', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'service_tier': 'default'}, id='run--cb980a8c-6db8-4374-a63b-779e9278a8ee-0', usage_metadata={'input_tokens': 24, 'output_tokens': 182, 'total_tokens': 206, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_template(\"'{topic}'을 한문장으로 요약해줘\")\n",
        "llm = ChatOpenAI(model = 'gpt-4o-mini')\n",
        "chain = prompt | llm\n",
        "\n",
        "inputs = [\n",
        "    {'topic' : '인공지능'},\n",
        "    {'topic' : '딥러닝'},\n",
        "    {'topic' : '머신러닝'},\n",
        "]\n",
        "\n",
        "# 여러 입력을 동시에 처리하는 batch\n",
        "result = chain.batch(inputs)\n",
        "\n",
        "for i, res in enumerate(result, 1):\n",
        "    print(i, res.content)"
      ],
      "metadata": {
        "id": "WdrwyZQ3n9C9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03284435-741f-403f-dff7-95bdc06a4a89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 인공지능은 기계가 인간의 학습, 문제 해결, 판단 등의 인지적 기능을 모방하여 수행하는 기술입니다.\n",
            "2 딥러닝은 인공지능의 한 분야로, 신경망을 통한 대량의 데이터를 학습하여 복잡한 패턴과 인사이트를 추출하는 기술이다.\n",
            "3 머신러닝은 데이터에서 패턴을 학습하여 예측이나 결정을 자동으로 수행하는 인공지능의 한 분야입니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 후처리 블록 추가 - 포멧팅\n",
        "from langchain.schema.runnable import RunnableLambda\n",
        "\n",
        "# 1) 프롬프트 템플릿\n",
        "prompt2 = ChatPromptTemplate.from_template(\"'{topic}'을 한 문장으로 설명해줘\")\n",
        "\n",
        "# 2) 후처리(포멧팅) RunnableLambda\n",
        "# 프롬프트만 가지고서는 템플릿적용이 잘 안된다 -> lambda를 활용해서 컴퓨터가 이해할수 있는 구조를 정하는 것\n",
        "pretty = RunnableLambda(lambda x: f\"요약: {x.content}\")\n",
        "\n",
        "# 3) LECL 파이프라인\n",
        "chain2 = prompt2 | llm | pretty\n",
        "\n",
        "# 4) 1번 실행\n",
        "print(chain2.invoke({'topic' : '인공지능'}))\n",
        "\n",
        "# 5) 배치 실행\n",
        "topics = [{\"topic\" : t} for t in ['ai','자연어처리','인공지능']]\n",
        "result = chain2.batch(topics)\n",
        "for r in result:\n",
        "    print(r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBGrPVSepk0J",
        "outputId": "bd27b274-4198-434f-dff5-d85ee4fbf9be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "요약: 인공지능은 인간의 지능을 모방하여 학습, 문제 해결, 의사 결정 등의 작업을 수행하는 컴퓨터 시스템이나 프로그램입니다.\n",
            "요약: AI(인공지능)는 인간의 지능을 모방하여 학습, 추론, 문제 해결 등의 작업을 수행하는 컴퓨터 시스템입니다.\n",
            "요약: 자연어처리(NLP)는 컴퓨터가 인간의 자연어를 이해하고 해석하며 생성할 수 있도록 돕는 인공지능의 한 분야입니다.\n",
            "요약: 인공지능은 인간의 지능을 시뮬레이션하여 학습, 문제 해결, 언어 이해 등의 작업을 수행하는 컴퓨터 시스템이나 프로그램입니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_multi = ChatPromptTemplate.from_template(\n",
        "    \"주제: {topic}\\n\"\n",
        "    \"요약을 {language}로 작성해줘.\"\n",
        ")\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "chain = prompt_multi | llm\n",
        "\n",
        "print(chain.invoke({\"topic\": \"인공지능\", \"language\": \"일본어\"}).content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bqYinptuprZ",
        "outputId": "d2f236d2-f2f1-4282-ea79-8838ca2d1d42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "人工知能（AI）は、コンピュータやシステムが人間の知能を模倣し、学習、思考、問題解決を行う技術です。AIはさまざまな分野で応用されており、例えば、医療、金融、自動運転、翻訳、そして日常生活の便利ツールなどがあります。近年、機械学習や深層学習の進歩により、AIの性能は飛躍的に向上していますが、その一方で倫理的な問題やプライバシーの懸念も重要な課題となっています。技術の進展とともに、AIの未来には多くの可能性と挑戦が存在しています。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_multi = ChatPromptTemplate.from_template(\n",
        "    \"다음 {article}에 대해서 요약해줘\"\n",
        "    \"출력형식은 다음과 같아\"\n",
        "    \"기사 제목을 작성해줘\"\n",
        "    \"전체 내용을 {n1}문장으로 요약해줘\"\n",
        "    \"핵심 요점을 {n2}가지로 작성해줘\"\n",
        ")\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "chain = prompt_multi | llm\n",
        "\n",
        "print(chain.invoke({\"article\": \"제목 : 오늘 李대통령·트럼프 회담, 공동 합의문 나올지 불투명 내용 : 이재명 대통령은 29일 오전 방한하는 도널드 트럼프 미국 대통령과 아시아·태평양경제협력체(APEC) 정상회의가 열리는 경주에서 두 번째 정상회담을 갖는다. 지난 8월 첫 회담 이후 두 달 만에 열리는 이번 정상회담은 한미 관세 후속 협상의 최대 쟁점인 3500억달러 투자 문제를 비롯해 한미 동맹, 북한 문제 등이 주요 의제로 다뤄질 예정이다. 특히 트럼프 대통령이 아시아 순방 중 연이어 “김정은과 만나고 싶다”고 밝힌 만큼, 이번 한미 정상회담의 대북 논의가 ‘트럼프·김정은 판문점 회동’으로 이어질 지 주목된다.\", \"n1\": \"2\", \"n2\": \"3\"}).content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbUY_WlwyBR-",
        "outputId": "fdc0cd9a-62eb-4a19-f942-f38cfe6e7bea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**기사 제목:** 오늘 李대통령·트럼프 회담, 공동 합의문 나올지 불투명\n",
            "\n",
            "**전체 내용 요약:** 이재명 대통령과 도널드 트럼프 미국 대통령은 29일 경주에서 두 번째 정상회담을 열며, 한미 동맹과 북한 문제 등 주요 사안을 논의할 예정입니다. 특히 트럼프 대통령이 북한과의 대화를 원하고 있어, 이번 회담이 향후 김정은과의 만남으로 이어질 가능성에 관심이 집중되고 있습니다.\n",
            "\n",
            "**핵심 요점:**\n",
            "1. 이재명 대통령과 트럼프 대통령의 두 번째 정상회담이 경주에서 개최된다.\n",
            "2. 주요 의제는 한미 동맹, 북한 문제, 그리고 3500억 달러 투자 문제 등이다.\n",
            "3. 트럼프 대통령의 북한과의 대화 의지로 인해 대북 논의가 중요성이 커지고 있다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.schema import StrOutputParser\n",
        "\n",
        "# 1️⃣ 프롬프트 정의\n",
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"다음 문장의 감정을 '긍정' 또는 '부정' 중 하나로 판단해줘.\\n문장: {sentence}\"\n",
        ")\n",
        "\n",
        "# 2️⃣ 모델 및 파서\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "parser = StrOutputParser()\n",
        "\n",
        "# 3️⃣ 체인 구성\n",
        "chain = prompt | llm | parser\n",
        "\n",
        "# 4️⃣ 실행\n",
        "print(chain.invoke({\"sentence\": \"오늘 하루가 너무 즐겁다!\"}))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQaMrK6uzUPw",
        "outputId": "e86c898d-0fad-4ef2-fe84-bc16918e4b69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문장의 감정은 '긍정'입니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
        "\n",
        "# 1️⃣ 결과 스키마 정의\n",
        "schemas = [\n",
        "    ResponseSchema(name=\"sentiment\", description=\"문장의 감정: positive 또는 negative\"),\n",
        "    ResponseSchema(name=\"reason\", description=\"이 판단을 내린 이유를 간단히 서술\"),\n",
        "]\n",
        "\n",
        "# 2️⃣ 파서 생성\n",
        "parser = StructuredOutputParser.from_response_schemas(schemas)\n",
        "format_instructions = parser.get_format_instructions()\n",
        "\n",
        "# 3️⃣ 프롬프트 생성 (형식 지시 포함)\n",
        "prompt_json = ChatPromptTemplate.from_template(\n",
        "    \"다음 문장의 감정을 분석하되, 반드시 JSON 형식으로 답변해줘.\\n\"\n",
        "    \"{format_instructions}\\n\\n문장: {sentence}\"\n",
        ")\n",
        "\n",
        "# 4️⃣ 체인 구성\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "chain = prompt_json | llm | parser\n",
        "\n",
        "# 5️⃣ 실행\n",
        "result = chain.invoke({\n",
        "    \"sentence\": \"비가 와서 기분이 우울하다.\",\n",
        "    \"format_instructions\": format_instructions\n",
        "})\n",
        "\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RdCuZGc1ro-",
        "outputId": "f8ca5046-77e0-48ab-ccfb-3f227e9aa652"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'sentiment': 'negative', 'reason': \"문장에서 '기분이 우울하다'는 표현이 사용되어 부정적인 감정을 나타내고 있습니다.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 조건 분기 langchain 챗봇"
      ],
      "metadata": {
        "id": "aL7RauhQJHRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 0) 라이브러리 호출\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema import StrOutputParser\n",
        "from langchain.output_parsers import StructuredOutputParser, ResponseSchema"
      ],
      "metadata": {
        "id": "rRV5aMJG1w02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) llm 호출\n",
        "llm = ChatOpenAI(model = 'gpt-4o-mini', temperature = 0)"
      ],
      "metadata": {
        "id": "MAYpKIzlJjf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) 첫번째 체인 - 요약 체인 : input - {text} - 일반 텍스트를 출력\n",
        "prompt_summary = ChatPromptTemplate.from_template(\n",
        "    \"'{text}'를 세 문장으로 요약해줘\"\n",
        ")\n",
        "# 첫번째 chain -> 텍스트를 세문장으로 요약해서 텍스트로 출력하는 Chain\n",
        "summary_chain = prompt_summary | llm | StrOutputParser()"
      ],
      "metadata": {
        "id": "STt1IB2pJqUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) 두번째 체인 - Json출력하는 체인을 구성\n",
        "# 1. 출력할 Json파일의 설계 - 스키마 - 구조(뼈대)\n",
        "\n",
        "# 뼈대 완성!\n",
        "schemas = [\n",
        "    ResponseSchema(name = 'sentiment', description= \"positive, negative\"),\n",
        "    ResponseSchema(name = 'reason', description= \"한 줄 이유\"),\n",
        "]\n",
        "# 위에서 schemas 설계한 스키마를 기준으로 LLM에서 출력된 결과를 JSON으로 변환하는 파서~!\n",
        "parser = StructuredOutputParser.from_response_schemas(schemas)\n",
        "# LLM에게서 지시할 형식에 대한 지시문을 작성 - 위에서 parser에 입력된 스키마 구성에 맞게 결과를 출력해!\n",
        "fmt = parser.get_format_instructions()"
      ],
      "metadata": {
        "id": "jakDUPhXLadC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. langchain 설계\n",
        "prompt_sentiment = ChatPromptTemplate.from_template(\n",
        "    \"다음 문장의 감정을 분석해서 JSON으로 답해줘.\"\n",
        "    \"{format_instructions} 문장 : {sentence}\"\n",
        ").partial(format_instructions = fmt) # fmt의 변수로 고정!\n",
        "\n",
        "sentiment_chain = prompt_sentiment | llm | parser\n",
        "\n",
        "# partial\n",
        "# chain.invoke({'sentence' : '오늘 너무 피곤하다', 'format_instructions' : fmt})\n",
        "# chain.invoke({'sentence' : '오늘 너무 피곤하다')"
      ],
      "metadata": {
        "id": "CQ10dzQ3NfZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 첫번째 Langchain - text만들어오면 요약\n",
        "* 두번째 format_instructions / sentence가 둘다 들어왔을때 거기에 대한 답변"
      ],
      "metadata": {
        "id": "t80KPGfiOCNc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5) 라우터! if문으로 chatbot 기능을 재구현\n",
        "def run_bot(mode, message):\n",
        "    if mode == 'summary':\n",
        "        return summary_chain.invoke({'text' : message})\n",
        "    elif mode == 'sentiment':\n",
        "        return sentiment_chain.invoke({'sentence' : message})\n",
        "    return \"지원 모드: summary | sentiment\"\n"
      ],
      "metadata": {
        "id": "8Jj05DLgOMGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6) 테스트\n",
        "print(run_bot(\"summary\", \"랭체인은 LLM을 효율적으로 만든 프레임워크야\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgu_lcd4P-2u",
        "outputId": "2c445f74-cd5e-414b-edf1-16d75765c7d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "랭체인은 대규모 언어 모델(LLM)을 효율적으로 개발할 수 있도록 돕는 프레임워크입니다. 이 프레임워크는 다양한 도구와 기능을 제공하여 모델의 성능을 극대화합니다. 이를 통해 개발자들은 더 빠르고 효과적으로 LLM을 구축하고 활용할 수 있습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(run_bot(\"sentiment\", \"오늘은 너무 피곤하고 우울해\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joglMH4-QNrs",
        "outputId": "a19439c7-486f-4880-be14-f053f39b615c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'sentiment': 'negative', 'reason': '피곤함과 우울함을 표현하고 있어 부정적인 감정이다.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sequential chain에 대해서 실습\n",
        "from langchain.chains import LLMChain, SequentialChain"
      ],
      "metadata": {
        "id": "nBMbaNGyQgTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1단계 프롬프트 설계\n",
        "summary_prompt = ChatPromptTemplate.from_template(\n",
        "    \"다음 문장을 3줄 이내로 요약해줘 {text}\"\n",
        ")\n",
        "\n",
        "summary_chain = LLMChain(\n",
        "    llm = llm,\n",
        "    prompt = summary_prompt,\n",
        "    output_key = 'summary'\n",
        ")"
      ],
      "metadata": {
        "id": "eoD12mzcYtMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2단계 번역에 대한 체인\n",
        "translate_prompt = ChatPromptTemplate.from_template(\n",
        "    \"다음 요약문을 영어로 자연스럽게 번역해줘 : {summary}\"\n",
        ")\n",
        "\n",
        "translate_chain = LLMChain(\n",
        "    llm = llm,\n",
        "    prompt = translate_prompt,\n",
        "    output_key = 'translation'\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "TRBQ-mjkZIci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3단계 번역에 대한 체인\n",
        "translate_prompt2 = ChatPromptTemplate.from_template(\n",
        "    \"공식적이고 전문적인 뉴스 요약버전으로 구성해줘: {text}\"\n",
        ")\n",
        "\n",
        "translate_chain2 = LLMChain(\n",
        "    llm = llm,\n",
        "    prompt = translate_prompt2,\n",
        "    output_key = 'translation2'\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "SPqS9hIDc7GN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3단계 번역에 대한 체인\n",
        "translate_prompt3 = ChatPromptTemplate.from_template(\n",
        "    \" 해당 내용을 일본어로 번역해줘: {translation2}\"\n",
        ")\n",
        "\n",
        "translate_chain3 = LLMChain(\n",
        "    llm = llm,\n",
        "    prompt = translate_prompt3,\n",
        "    output_key = 'translation3'\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "TBeDwWLNdE3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SequentialChain으로 연결\n",
        "# output은 이미 구성해놓았으니 invoke에서 input에 대한 key만 text로 구성하면 완료!\n",
        "\n",
        "chain = SequentialChain(\n",
        "    chains = [summary_chain, translate_chain, translate_chain2, translate_chain3],\n",
        "    input_variables = ['text'],\n",
        "    output_variables = ['summary', 'translation', 'translation2', 'translation3']\n",
        ")"
      ],
      "metadata": {
        "id": "BWb-wMj8bJjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"\"\"\n",
        "아시아태평양경제협력체(APEC) 정상회의를 계기로 방한한 도널드 트럼프 미국 대통령이 29일 ‘2025 경주 APEC CEO 서밋’ 특별 연설로 1박 2일 일정을 시작했다.\n",
        "이날 오후 1시쯤 APEC CEO 서밋이 열리는 경주 예술의전당 화랑홀의 연단에 오른 트럼프 대통령은 “내가 있는 이 나라는 매우 특별한 나라”라며 “한국은 미국의 소중한 친구이자 우방국”이라고 했다.\n",
        "트럼프 대통령은 “비전을 가진 혁신가들, 가장 뛰어난 각지에서 오신 분들 앞에 서게 돼 특별한 의미가 있다”며 “한국에 오게 돼 정말 기쁘다”고 했다.\n",
        "이어 “이재명 대통령은 정말 훌륭한 분”이라며 “오늘 오후에 별도로 만날 예정”이라고 밝혔다. 이어 그는 한국에 대해서도 “한국 국민은 경제적 기적을 만들었다”며 “배울 게 많고 존경할 만한 국가”라고 했다. 이어 “산업 강국이자, 자유로운 사회이고, 민주주의와 번영하는 문명을 가졌다”고 했다.\n",
        "\"\"\"\n",
        "\n",
        "result = chain.invoke({\"text\": input_text})\n",
        "print(result['summary'])\n",
        "print(result['translation'])\n",
        "print(result['translation2'])\n",
        "print(result['translation3'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJrbaJBjaNpF",
        "outputId": "52055a4e-5869-4366-fd59-19b1511b1732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "도널드 트럼프 미국 대통령이 APEC 정상회의 참석을 위해 방한하여 '2025 경주 APEC CEO 서밋'에서 특별 연설을 했다. 그는 한국을 미국의 소중한 친구로 언급하며, 이재명 대통령과의 만남을 예고하고 한국의 경제적 성과와 민주주의를 높이 평가했다. 트럼프 대통령은 한국 방문에 큰 기쁨을 느낀다고 밝혔다.\n",
            "U.S. President Donald Trump visited South Korea to attend the APEC summit, where he delivered a special speech at the '2025 Gyeongju APEC CEO Summit.' He referred to South Korea as a valuable friend of the United States and hinted at a meeting with President Lee Jae-myung, praising South Korea's economic achievements and democracy. President Trump expressed his great pleasure in visiting South Korea.\n",
            "도널드 트럼프 미국 대통령이 아시아태평양경제협력체(APEC) 정상회의 참석을 위해 방한하여 29일 '2025 경주 APEC CEO 서밋'에서 특별 연설을 진행했다. 트럼프 대통령은 경주 예술의전당 화랑홀에서 \"한국은 미국의 소중한 친구이자 우방국\"이라며 한국에 대한 긍정적인 평가를 내렸다. 그는 \"비전을 가진 혁신가들 앞에 서게 되어 특별한 의미가 있다\"며 한국 방문에 대한 기쁨을 표현했다. 또한 이재명 대통령에 대한 칭찬과 함께, 한국 국민의 경제적 성취를 높이 평가하며 \"산업 강국이자 자유로운 사회\"라고 강조했다.\n",
            "ドナルド・トランプ米国大統領がアジア太平洋経済協力体（APEC）首脳会議に出席するために韓国を訪れ、29日に「2025慶州APEC CEOサミット」で特別講演を行った。トランプ大統領は慶州芸術の殿堂ホールで「韓国はアメリカの大切な友人であり、同盟国だ」と述べ、韓国に対する肯定的な評価を示した。彼は「ビジョンを持った革新者たちの前に立つことは特別な意味がある」と語り、韓国訪問への喜びを表現した。また、イ・ジェミョン大統領への称賛とともに、韓国国民の経済的成果を高く評価し、「産業強国であり自由な社会」と強調した。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0v9ad4NCb9rs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate"
      ],
      "metadata": {
        "id": "1NwtKwwbgyip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "buffer_memory = ConversationBufferMemory(memory_key=\"history\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2iYaE5Agyf-",
        "outputId": "4e9d9f31-f070-4bcc-86ca-5a1883aba2fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3589186201.py:4: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  buffer_memory = ConversationBufferMemory(memory_key=\"history\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"너는 대화 요약가야. 항상 한국어로 두문장 이내로 간결하게 요약한다.\"),\n",
        "    (\"user\"  , \"이전 요약 {summary} 새로운 대화 {new_lines} 업데이트 된 한국어 요약 : \")\n",
        "])"
      ],
      "metadata": {
        "id": "a_CNBlrgqb0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summary 메모리로 대체\n",
        "from langchain.memory import ConversationSummaryMemory\n",
        "\n",
        "# 요약을 해야하기 때문에 llm이 활용 -> 대신 메모리가 절약 -> 향후 토큰이 절약\n",
        "summary = ConversationSummaryMemory(\n",
        "    llm=ChatOpenAI(model = 'gpt-4o-mini'),\n",
        "    prompt=summary_prompt,\n",
        "    memory_key = 'history',\n",
        "    return_messages = False\n",
        ")"
      ],
      "metadata": {
        "id": "Iz3bbMV-pX8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory"
      ],
      "metadata": {
        "id": "DcGE35Ctg5Wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 가장 기본적인 메모리 구성!\n",
        "# 이 메모리는 전체 메세지를 기억하는 메모리!\n",
        "\n",
        "llm = ChatOpenAI(model = 'gpt-4o-mini')\n",
        "buffer_memory = ConversationBufferMemory(memory_key = 'history')"
      ],
      "metadata": {
        "id": "m0om7U9zl48E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Key형식으로 메모리 내용이 들어갈 부분을 구현!\n",
        "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "너는 친근한 한국어 대화 파트너야\n",
        "이전의 대화를 기억해서 맥락을 이어서 대화를 해줘\n",
        "{history}\n",
        "\n",
        "사용자 : {input}\n",
        "\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "xZVdi2JQmB0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 메모리를 저장하는 LLM 챗봇\n",
        "def talk_with_buffer(user_input):\n",
        "    # 1) 이전 히스토리 불러오기\n",
        "    # load_memory_variables{} -> 메모리에 저장된 내용을 {} 딕셔너리 형태로 가져온다.\n",
        "    # .get(\"history\") -> history 키에 해당하는 대화 문자열을 꺼낸다. 없으면 빈 문자열을 가져온다.\n",
        "    history = buffer_memory.load_memory_variables({}).get(\"history\",\"\")\n",
        "    # 2) 프롬프트를 완성\n",
        "    msg = prompt.format(history = history, input = user_input)\n",
        "    # 3) 모델을 호출\n",
        "    answer = llm.invoke(msg).content\n",
        "    # 4) 대화의 내용을 저장\n",
        "    buffer_memory.save_content({'input': user_input}, {'output' : answer})\n",
        "\n",
        "    return answer"
      ],
      "metadata": {
        "id": "j9oeqyvkmjbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 메모리를 저장하는 LLM 챗봇\n",
        "def talk_with_buffer(user_input):\n",
        "    # 1) 이전 히스토리 불러오기\n",
        "    # load_memory_variables{} -> 메모리에 저장된 내용을 {} 딕셔너리 형태로 가져온다.\n",
        "    # .get(\"history\") -> history 키에 해당하는 대화 문자열을 꺼낸다. 없으면 빈 문자열을 가져온다.\n",
        "    history = summary.load_memory_variables({}).get(\"history\",\"\")\n",
        "    # 2) 프롬프트를 완성\n",
        "    msg = prompt.format(history = history, input = user_input)\n",
        "    # 3) 모델을 호출\n",
        "    answer = llm.invoke(msg).content\n",
        "    # 4) 대화의 내용을 저장\n",
        "    summary.save_context({'input': user_input}, {'output' : answer})\n",
        "\n",
        "    return answer"
      ],
      "metadata": {
        "id": "lFMfQ5sSr1KE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(talk_with_buffer(\"안녕 내 이름은 김진환이야\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkdef0MCoScX",
        "outputId": "f787006c-7880-4c80-c9f8-9e1d02da9d08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요, 김진환님! 반가워요. 오늘 기분이 어떠세요?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(talk_with_buffer(\"내 이름을 알고 있니?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoPoHnX-oqng",
        "outputId": "58483097-efaa-4216-c10a-95a1a151552f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI: 안녕하세요, 김진환님! 네, 당신의 이름을 기억하고 있어요. 오늘 기분은 어떠신가요?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(summary.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "io_8yMo9oYIj",
        "outputId": "54b88a55-a3e4-4fd5-a182-34d1fa36e348"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI가 김진환님의 이름을 기억하고 있으며, 오늘 기분을 묻고 있다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S6yjFjHeo21L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}