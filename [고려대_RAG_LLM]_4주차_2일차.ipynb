{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xi41h0AsJDft"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ë°ì´í„°ê°€ ì œëŒ€ë¡œ ì½í˜€ì§€ëŠ”ì§€ í™•ì¸\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"customer_db.csv\")\n",
        "print(df[df['name'] == 'ê¹€ë¯¼ìˆ˜'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Al89nu-PrBg",
        "outputId": "178dec1f-201d-4585-8bd8-dbeeb89b4594"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   customer_id name  age marital_status  children_count  income region  \\\n",
            "0            1  ê¹€ë¯¼ìˆ˜   35             ê¸°í˜¼               2    6200     ì„œìš¸   \n",
            "\n",
            "   has_house  has_disabled_member  subscription_years  savings_count  \\\n",
            "0      False                False                   8             96   \n",
            "\n",
            "  account_type  \n",
            "0     ì£¼íƒì²­ì•½ì¢…í•©ì €ì¶•  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pandas Queryì— ëŒ€í•œ ì´í•´\n",
        "# ê¸°ì¡´ ì¿¼ë¦¬ ì²˜ë¦¬ ë°©ë²• df[df['name'] == ê¹€ë¯¼ìˆ˜]\n",
        "\n",
        "# ìë…€ìˆ˜ 2ëª… ì´ìƒ + ë¬´ì£¼íƒ + ì†Œë“ 6ì²œë§Œì› ì´ìƒì¸ ê³ ê°\n",
        "df_2 = df.query(\"children_count >= 2 and has_house == False and income > 6000\")\n",
        "\n",
        "print(df_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CyMnRrFQl-3",
        "outputId": "fc09d926-5894-4530-c34c-390b38bbf306"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   customer_id name  age marital_status  children_count  income region  \\\n",
            "0            1  ê¹€ë¯¼ìˆ˜   35             ê¸°í˜¼               2    6200     ì„œìš¸   \n",
            "2            3  ë°•ì˜í¬   40             ê¸°í˜¼               3    7000     ëŒ€ì „   \n",
            "9           10  í™ì§€í˜„   41             ê¸°í˜¼               3    6900     ë¶€ì‚°   \n",
            "\n",
            "   has_house  has_disabled_member  subscription_years  savings_count  \\\n",
            "0      False                False                   8             96   \n",
            "2      False                False                  10            120   \n",
            "9      False                False                  11            132   \n",
            "\n",
            "  account_type  \n",
            "0     ì£¼íƒì²­ì•½ì¢…í•©ì €ì¶•  \n",
            "2     ì£¼íƒì²­ì•½ì¢…í•©ì €ì¶•  \n",
            "9     ì£¼íƒì²­ì•½ì¢…í•©ì €ì¶•  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain langchain_community langchain_openai langchain-experimental chromadb tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgkuSJwtRqq4",
        "outputId": "6cdbb208-0a68-4aa8-89be-fa62309127af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m20.8/20.8 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "google-adk 1.17.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.38.0 which is incompatible.\n",
            "google-adk 1.17.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.38.0 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.38.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_experimental.agents.agent_toolkits.pandas.base import create_pandas_dataframe_agent\n",
        "from langchain_openai import ChatOpenAI"
      ],
      "metadata": {
        "id": "IQxr7cIGTgxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model = 'gpt-4o-mini')"
      ],
      "metadata": {
        "id": "EwOxM0DRT3g7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PREFIX = (\n",
        "    \"ë„ˆëŠ” pandasë§Œ ì‚¬ìš©í•´ df(DataFrame)ì—ì„œ ë‹µì„ êµ¬í•´. \"\n",
        "    \"í•œ ì¤„ ìš”ì•½ìœ¼ë¡œë§Œ ë‹µí•˜ê³ , í‘œ/ê·¸ë˜í”„ëŠ” ìƒì„±í•˜ì§€ ë§ˆ. \"\n",
        "    \"ì‹¤í–‰ì´ ì‹¤íŒ¨í•˜ë©´ ì¦‰ì‹œ ê°„ë‹¨í•œ ìš”ì•½ìœ¼ë¡œ fallbackí•´.\"\n",
        ")"
      ],
      "metadata": {
        "id": "2V5G9ETpWgz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pandas Agent ìƒì„±\n",
        "agent = create_pandas_dataframe_agent(\n",
        "    llm,\n",
        "    df,\n",
        "    verbose = True,\n",
        "    allow_dangerous_code = True,\n",
        "    max_iterations = 15,\n",
        "    max_execution_time= 60,\n",
        "    prefix=PREFIX\n",
        ")"
      ],
      "metadata": {
        "id": "URS7D2xmT_Um"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì§ˆì˜ í•¨ìˆ˜\n",
        "def ask(q):\n",
        "    res = agent.invoke(q)\n",
        "    return res if isinstance(res, str) else res.get(\"output\", str(res))"
      ],
      "metadata": {
        "id": "2rnrvHxDUPV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ask(\"ê¹€ë¯¼ìˆ˜ì˜ ë‚˜ì´, ê²°í˜¼ìƒíƒœ, ì†Œë“, ìë…€ìˆ˜ë¥¼ í•œì¤„ë¡œ ìš”ì•½í•´ì¤˜\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0iv7-XPUYKR",
        "outputId": "811ce1b9-b786-47f4-fbf6-c98020103af7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to extract ê¹€ë¯¼ìˆ˜'s age, marital status, income, and children count from the DataFrame and summarize it in one line.  \n",
            "Action: python_repl_ast  \n",
            "Action Input: df.loc[df['name'] == 'ê¹€ë¯¼ìˆ˜', ['age', 'marital_status', 'income', 'children_count']].iloc[0].to_string(index=False)  \u001b[0m\u001b[36;1m\u001b[1;3m  35\n",
            "  ê¸°í˜¼\n",
            "6200\n",
            "   2\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer  \n",
            "Final Answer: ê¹€ë¯¼ìˆ˜ëŠ” 35ì„¸, ê¸°í˜¼ì´ë©°, ì†Œë“ì€ 6200ì´ê³  ìë…€ëŠ” 2ëª…ì…ë‹ˆë‹¤.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'input': 'ê¹€ë¯¼ìˆ˜ì˜ ë‚˜ì´, ê²°í˜¼ìƒíƒœ, ì†Œë“, ìë…€ìˆ˜ë¥¼ í•œì¤„ë¡œ ìš”ì•½í•´ì¤˜', 'output': 'ê¹€ë¯¼ìˆ˜ëŠ” 35ì„¸, ê¸°í˜¼ì´ë©°, ì†Œë“ì€ 6200ì´ê³  ìë…€ëŠ” 2ëª…ì…ë‹ˆë‹¤.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ask(\"ì§€ì—­ë³„ í‰ê·  ì†Œë“ì„ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬í•´ì„œ ë³´ì—¬ì¤˜\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3-H65oza5i6",
        "outputId": "98261652-d43b-4919-dc0c-8c7f8ac05993"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: ì§€ì—­ë³„ í‰ê·  ì†Œë“ì„ ê³„ì‚°í•˜ê³ , ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬í•´ì•¼ í•œë‹¤.  \n",
            "Action: python_repl_ast  \n",
            "Action Input: df.groupby('region')['income'].mean().sort_values(ascending=False)  \u001b[0m\u001b[36;1m\u001b[1;3mregion\n",
            "ê´‘ì£¼    7200.0\n",
            "ëŒ€ì „    7000.0\n",
            "ì„¸ì¢…    5800.0\n",
            "ë¶€ì‚°    5700.0\n",
            "ì¸ì²œ    5200.0\n",
            "ì„œìš¸    5150.0\n",
            "ëŒ€êµ¬    5100.0\n",
            "ê²½ê¸°    4800.0\n",
            "Name: income, dtype: float64\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer  \n",
            "Final Answer: ì§€ì—­ë³„ í‰ê·  ì†Œë“ì€ ê´‘ì£¼ 7200, ëŒ€ì „ 7000, ì„¸ì¢… 5800, ë¶€ì‚° 5700, ì¸ì²œ 5200, ì„œìš¸ 5150, ëŒ€êµ¬ 5100, ê²½ê¸° 4800 ìˆœìœ¼ë¡œ ë†’ìŠµë‹ˆë‹¤.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'input': 'ì§€ì—­ë³„ í‰ê·  ì†Œë“ì„ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬í•´ì„œ ë³´ì—¬ì¤˜', 'output': 'ì§€ì—­ë³„ í‰ê·  ì†Œë“ì€ ê´‘ì£¼ 7200, ëŒ€ì „ 7000, ì„¸ì¢… 5800, ë¶€ì‚° 5700, ì¸ì²œ 5200, ì„œìš¸ 5150, ëŒ€êµ¬ 5100, ê²½ê¸° 4800 ìˆœìœ¼ë¡œ ë†’ìŠµë‹ˆë‹¤.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ask(\"ë¬´ì£¼íƒ ê³ ê° ì¤‘ ì†Œë“ ìƒìœ„ 3ëª…ì„ ë³´ì—¬ì¤˜\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjuwVtBRUyOJ",
        "outputId": "c99c98b4-87b0-4793-80ea-0274405af8e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: ë¬´ì£¼íƒ ê³ ê°ì„ í•„í„°ë§í•˜ê³ , ì†Œë“ì„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ 3ëª…ì„ ì¶”ì¶œí•´ì•¼ í•œë‹¤.\n",
            "Action: python_repl_ast\n",
            "Action Input: df[df['has_house'] == False].nlargest(3, 'income')\u001b[0m\u001b[36;1m\u001b[1;3m   customer_id name  age marital_status  children_count  income region  \\\n",
            "2            3  ë°•ì˜í¬   40             ê¸°í˜¼               3    7000     ëŒ€ì „   \n",
            "9           10  í™ì§€í˜„   41             ê¸°í˜¼               3    6900     ë¶€ì‚°   \n",
            "0            1  ê¹€ë¯¼ìˆ˜   35             ê¸°í˜¼               2    6200     ì„œìš¸   \n",
            "\n",
            "   has_house  has_disabled_member  subscription_years  savings_count  \\\n",
            "2      False                False                  10            120   \n",
            "9      False                False                  11            132   \n",
            "0      False                False                   8             96   \n",
            "\n",
            "  account_type  \n",
            "2     ì£¼íƒì²­ì•½ì¢…í•©ì €ì¶•  \n",
            "9     ì£¼íƒì²­ì•½ì¢…í•©ì €ì¶•  \n",
            "0     ì£¼íƒì²­ì•½ì¢…í•©ì €ì¶•  \u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: ë¬´ì£¼íƒ ê³ ê° ì¤‘ ì†Œë“ ìƒìœ„ 3ëª…ì€ ë°•ì˜í¬(7000), í™ì§€í˜„(6900), ê¹€ë¯¼ìˆ˜(6200)ì´ë‹¤.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'input': 'ë¬´ì£¼íƒ ê³ ê° ì¤‘ ì†Œë“ ìƒìœ„ 3ëª…ì„ ë³´ì—¬ì¤˜', 'output': 'ë¬´ì£¼íƒ ê³ ê° ì¤‘ ì†Œë“ ìƒìœ„ 3ëª…ì€ ë°•ì˜í¬(7000), í™ì§€í˜„(6900), ê¹€ë¯¼ìˆ˜(6200)ì´ë‹¤.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PII_BLOCK = {\"ì—°ì°©ì²˜\", \"ì£¼ë¯¼\", \"ì´ë©”ì¼\", \"ì „í™”\", \"ì£¼ì†Œ\"}\n",
        "\n",
        "def safe_ask(q):\n",
        "    if any(k in q for k in PII_BLOCK):\n",
        "        return \"ê°œì¸ì •ë³´ í•­ëª©ì€ ì¡°íšŒí• ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
        "    return ask(q)"
      ],
      "metadata": {
        "id": "75mmcEPAVBcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(safe_ask(\"ê¹€ë¯¼ìˆ˜ ê³ ê°ì˜ ì£¼ì†Œë¥¼ ì•Œë ¤ì¤˜\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_89rmHQdRqf",
        "outputId": "0b28c84f-b277-4605-ebd2-cf3548303b57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ê°œì¸ì •ë³´ í•­ëª©ì€ ì¡°íšŒí• ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Structured RAG HR ì±—ë´‡ ì‹¤ìŠµ êµì•ˆ"
      ],
      "metadata": {
        "id": "f1t2uHxHfp_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. ì§ì› ë°ì´í„° ë² ì´ìŠ¤ import\n",
        "df = pd.read_csv(\"employee_db.csv\")"
      ],
      "metadata": {
        "id": "jn5065rDdUEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. ì •ì±… ë¬¸ì„œ import / md/ txt / docx / hwp / excel / csv / parquet\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "\n",
        "docs = TextLoader('company_policy.md', encoding = 'utf-8').load()\n",
        "print(len(docs))\n",
        "print(docs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jd2DGfVCf-Je",
        "outputId": "ec76d6f9-7520-4213-aafd-22e1d9351fe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "page_content='# íšŒì‚¬ ë‚´ê·œ (ìš”ì•½ë³¸) â€” íœ´ê°€Â·ì—°ë´‰ìƒìŠ¹ë¥ Â·ì—°ì°¨ ê·œì •\n",
            "\n",
            "> ë³¸ ë¬¸ì„œëŠ” ì‹¤ìŠµìš© ìš”ì•½ë³¸ì…ë‹ˆë‹¤. ì‹¤ì œ ì •ì±…ê³¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
            "\n",
            "## 1. ì§ê¸‰ ì²´ê³„\n",
            "- ì‚¬ì› â†’ ëŒ€ë¦¬ â†’ ê³¼ì¥ â†’ ì°¨ì¥ â†’ ë¶€ì¥\n",
            "\n",
            "## 2. ì—°ì°¨ íœ´ê°€ (ê¸°ë³¸)\n",
            "- ì‚¬ì›: ì—° 15ì¼\n",
            "- ëŒ€ë¦¬: ì—° 16ì¼\n",
            "- ê³¼ì¥: ì—° 18ì¼\n",
            "- ì°¨ì¥: ì—° 20ì¼\n",
            "- ë¶€ì¥: ì—° 22ì¼\n",
            "\n",
            "### 2.1 ê·¼ì† ê°€ì‚°\n",
            "- ê·¼ì† 3ë…„ ì´ìƒ: +1ì¼\n",
            "- ê·¼ì† 5ë…„ ì´ìƒ: +2ì¼\n",
            "- ê·¼ì† 10ë…„ ì´ìƒ: +4ì¼ (ì¤‘ë³µ ë¶ˆê°€, ìµœëŒ“ê°’ ê¸°ì¤€ìœ¼ë¡œ ì ìš©)\n",
            "\n",
            "### 2.2 ì´ì›” ê·œì •\n",
            "- ë¯¸ì‚¬ìš© ì—°ì°¨ ìµœëŒ€ 5ì¼ ì´ì›” ê°€ëŠ¥ (ì°¨ë…„ë„ 6ì›” 30ì¼ê¹Œì§€ ì‚¬ìš©)\n",
            "\n",
            "### 2.3 íŠ¹ë³„íœ´ê°€\n",
            "- ì¶œì‚°(ë³¸ì¸): 90ì¼(ë²•ì • ê¸°ì¤€ì— ë”°ë¦„) â€” ë³„ë„ ê´€ë¦¬\n",
            "- ë°°ìš°ì ì¶œì‚°: 10ì¼\n",
            "- ìë…€ ëŒë´„: ì—° 3ì¼ (ë¯¸ì„±ë…„ ìë…€ ë³´ìœ ìë§Œ)\n",
            "\n",
            "## 3. ì—°ë´‰ ìƒìŠ¹ë¥  (ê¸°ë³¸ ê°€ì´ë“œ)\n",
            "- ì‚¬ì›: 3~5%\n",
            "- ëŒ€ë¦¬: 4~6%\n",
            "- ê³¼ì¥: 5~7%\n",
            "- ì°¨ì¥: 4~6%\n",
            "- ë¶€ì¥: 3~5%\n",
            "\n",
            "### 3.1 ì„±ê³¼ ê°€ì¤‘ì¹˜ (Performance Multiplier)\n",
            "- A: +2%p\n",
            "- B: +0%p\n",
            "- C: -1%p (ë‹¨, í•˜í•œ 0% ë³´ì¥)\n",
            "\n",
            "> ì˜ˆ) ëŒ€ë¦¬(B)ì˜ ê¸°ë³¸ 4~6% â†’ BëŠ” +0%pì´ë¯€ë¡œ 4~6% ìœ ì§€\n",
            "> ì˜ˆ) ê³¼ì¥(A)ì˜ ê¸°ë³¸ 5~7% â†’ AëŠ” +2%p â†’ 7~9%\n",
            "\n",
            "## 4. ìŠ¹ì§„(í”„ë¡œëª¨ì…˜) ì°¸ê³ \n",
            "- ì‚¬ì›â†’ëŒ€ë¦¬: ìµœì†Œ ê·¼ì† 2ë…„ & ìµœê·¼ 2ê°œë…„ í‰ê·  í‰ê°€ B ì´ìƒ\n",
            "- ëŒ€ë¦¬â†’ê³¼ì¥: ìµœì†Œ ê·¼ì† 4ë…„ & ìµœê·¼ 2ê°œë…„ í‰ê·  í‰ê°€ B ì´ìƒ\n",
            "- ê³¼ì¥â†’ì°¨ì¥: ìµœì†Œ ê·¼ì† 5ë…„ & ìµœê·¼ 2ê°œë…„ í‰ê·  í‰ê°€ B ì´ìƒ\n",
            "- ì°¨ì¥â†’ë¶€ì¥: ìµœì†Œ ê·¼ì† 6ë…„ & ìµœê·¼ 3ê°œë…„ í‰ê·  í‰ê°€ B ì´ìƒ\n",
            "\n",
            "## 5. ê³„ì•½ì§/ì›ê²©\n",
            "- ê³„ì•½ì§: ì—°ì°¨ 11ì¼(ë¹„ë¡€ ì ìš© ê°€ëŠ¥), ì„±ê³¼ê°€ì¤‘ì¹˜ ìµœëŒ€ +0%p\n",
            "- ì™„ì „ ì›ê²©: ì—°ì°¨ ë™ì¼, ì¶œê·¼ ì˜ë¬´ ì—†ìŒ(íŒ€ í•©ì˜ ìš°ì„ )\n",
            "\n",
            "## 6. FAQ í‚¤ì›Œë“œ\n",
            "- \"ì—°ì°¨\", \"ì´ì›”\", \"ìë…€\", \"ë°°ìš°ì ì¶œì‚°\", \"ì—°ë´‰ ìƒìŠ¹ë¥ \", \"ì„±ê³¼\", \"ìŠ¹ì§„\", \"ê³„ì•½ì§\", \"ì›ê²©\"' metadata={'source': 'company_policy.md'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ì •ì±… ë¬¸ì„œì— ëŒ€í•œ ì„ë² ë”©\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "miy7qYZ6gj7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# chunk size = 700 (500~1000) chunk_overlap (50 ~ 300)\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size = 700, chunk_overlap = 100)\n",
        "splits = splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "voDHPkl6hXaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = OpenAIEmbeddings(model='text-embedding-3-small')\n",
        "vectordb = Chroma.from_documents(splits, embedding)\n",
        "retriever = vectordb.as_retriever(search_kwargs={\"k\" : 3})"
      ],
      "metadata": {
        "id": "zWK7qsFSiCP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# íŒë‹¤ìŠ¤ ì—ì´ì „íŠ¸ ë§Œë“¤ê¸°!"
      ],
      "metadata": {
        "id": "L_5TFhD8nKuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PREFIX = (\n",
        "    \"ë„ˆëŠ” pandasë§Œ ì‚¬ìš©í•´ df(DataFrame)ì—ì„œ ë‹µì„ êµ¬í•´. \"\n",
        "    \"í•œ ì¤„ ìš”ì•½ìœ¼ë¡œë§Œ ë‹µí•˜ê³ , í‘œ/ê·¸ë˜í”„ëŠ” ìƒì„±í•˜ì§€ ë§ˆ. \"\n",
        "    \"ì‹¤í–‰ì´ ì‹¤íŒ¨í•˜ë©´ ì¦‰ì‹œ ê°„ë‹¨í•œ ìš”ì•½ìœ¼ë¡œ fallbackí•´.\"\n",
        ")\n",
        "\n",
        "from langchain_experimental.agents.agent_toolkits.pandas.base import create_pandas_dataframe_agent\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model = 'gpt-4o-mini')\n",
        "\n",
        "emp_agent = create_pandas_dataframe_agent(\n",
        "    llm,\n",
        "    df,\n",
        "    verbose = False,\n",
        "    allow_dangerous_code= True,\n",
        "    prefix=PREFIX\n",
        ")"
      ],
      "metadata": {
        "id": "0f7WMqlIm97d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emp_agent.invoke(\"Aë“±ê¸‰ ì‚¬ì›ì˜ í‰ê·  ì—°ë´‰ì„ ì•Œë ¤ì¤˜\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ha8ic7CKn3ec",
        "outputId": "6e506c0a-a4ed-406b-89d2-c3dbc85cb8cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'Aë“±ê¸‰ ì‚¬ì›ì˜ í‰ê·  ì—°ë´‰ì„ ì•Œë ¤ì¤˜', 'output': 'Aë“±ê¸‰ ì‚¬ì›ì˜ í‰ê·  ì—°ë´‰ì€ 61.33ë°±ë§Œ ì›ì´ë‹¤.'}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG + ì§ì›ë°ì´í„°ë¥¼ í†µí•©í•˜ëŠ” ì²´ì¸"
      ],
      "metadata": {
        "id": "5T2cTIYnpCDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RunnableParallel ë³‘ë ¬ì²˜ë¦¬ - batch()\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ],
      "metadata": {
        "id": "eCC55tcDoNFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "ë„ˆëŠ” HRì „ë¬¸ê°€ì•¼.\n",
        "[ì§ì› ìš”ì•½]\n",
        "{emp_summary}\n",
        "\n",
        "[ì •ì±… ê·¼ê±°]\n",
        "{policy_snippets}\n",
        "\n",
        "[ì‚¬ìš©ì ì§ˆë¬¸]\n",
        "{question}\n",
        "\n",
        "ì¶œë ¥ í˜•ì‹:\n",
        "- ì •ì±…ì— ëŒ€í•œ ìš”ì•½:\n",
        "- ê³„ì‚°/ê·œì •ì— ëŒ€í•œ ì ìš©:\n",
        "- ê²°ë¡ (í•œì¤„) :\n",
        "\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "OnzsXwrOpauJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ë³¸ê²©ì ì¸ ì²´ì¸ êµ¬ì„±"
      ],
      "metadata": {
        "id": "C2P7dBb6qUSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. SQLì— ëŒ€í•œ ì²´ì¸ ì¤€ë¹„ (ì‚¬ì „ ì§ì› ì •ë³´ ì¤€ë¹„)\n",
        "# qì— ì‘ì„±í•œ ì§ˆì˜ëŒ€ë¡œ ì§ì›ì— ëŒ€í•œ ì •ë³´ë¥¼ ì‘ì„±í•´ì£¼ëŠ” ë¶€ë¶„!\n",
        "\n",
        "def summarize_employee(name):\n",
        "    q = f\"{name} ì§ì›ì˜ ì§ê¸‰, ê·¼ì†ì—°ìˆ˜(years_of_service), ì„±ê³¼ë“±ê¸‰(performance), ë‚¨ì€ ì—°ì°¨(remaining_leave), ê¸°ë³¸ì—°ë´‰(base_salary_mkrw)ë¥¼ í•œì¤„ë¡œ ìš”ì•½í•´ì¤˜\"\n",
        "    return emp_agent.invoke(q)"
      ],
      "metadata": {
        "id": "9zBrmCX8qFZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. ì •ì±…ì— ëŒ€í•œ ì²´ì¸ ì¤€ë¹„\n",
        "def search_policy(query):\n",
        "    return retriever.get_relevant_documents(query)"
      ],
      "metadata": {
        "id": "t--03HjZq-5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. retrieverë¡œ 3ê°€ì§€ ì¶”ì¶œëœ ìë£Œì— ëŒ€í•´ì„œ 1ê°œì˜ í…ìŠ¤íŠ¸ íŒŒì¼í™”\n",
        "def format_docs(docs):\n",
        "    return(\"\\n----\\n\".join([d.page_content[:300] for d in docs]))"
      ],
      "metadata": {
        "id": "c72q4SnRrZHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Langchain êµ¬ì¶•"
      ],
      "metadata": {
        "id": "-ZIq7rjvsQWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RunnableParallel - ë‘ê°€ì§€ ì‘ì—…ì„ ë³‘ë ¬ ì‹¤í–‰ì„ í•´ì„œ ìˆœì°¨ì ì¸ ì‹¤í–‰ì´ ì•„ë‹Œ ë™ì‹œì— ì„œë¡œ ë‹¤ë¥¸ ë‘ ì—ì´ì „íŠ¸ê°€ ì‹¤í–‰ë˜ë„ë¡\n",
        "# RunnablePassthrough.assign policy_docs ë³€ìˆ˜ -> policy_snippets ë³€ìˆ˜ë¡œ ìƒˆ í•„ë“œ ì ìš©(í• ë‹¹)\n",
        "# lambdaí•¨ìˆ˜ëŠ” summarize_employee, search_policy ìœ„ì—ì„œ ì •ì˜í•œ í•¨ìˆ˜ê°€ ì‹¤í–‰ë˜ë„ë¡ êµ¬í˜„!\n",
        "\n",
        "chain = (\n",
        "    RunnableParallel(\n",
        "        # SQLì¿¼ë¦¬ì—ì„œ ì‘ì„±ëœ ì§ì› ì •ë³´ë¥¼ emp_summaryë¡œ í• ë‹¹\n",
        "        emp_summary = lambda x: summarize_employee(x[\"name\"]),\n",
        "        # search_policyì—ì„œ ì§ˆë¬¸ì— ìœ ì‚¬í•œ ë‹µë³€ì„ policy_docsì— ë„£ëŠ”ë‹¤.\n",
        "        policy_docs = lambda x: search_policy(x[\"question\"]),\n",
        "        question = lambda x:x[\"question\"]\n",
        "    )\n",
        "    | RunnablePassthrough.assign(\n",
        "        policy_snippets = lambda x: format_docs(x[\"policy_docs\"])\n",
        "    )\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "A8VzfCx0sFIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = {\n",
        "    \"name\" : \"ê¹€ì§€í›ˆ\",\n",
        "    \"question\" : \"í•´ë‹¹ ì§ì›ì˜ ì„±ê³¼ì™€ ë‚¨ì€ ì—°ì°¨ë¥¼ ë³´ì—¬ì¤˜ ê·¸ë¦¬ê³  í•´ë‹¹ ì„±ê³¼ ë° ì—°ì°¨ ê·œì •ì„ ì§ê¸‰ì— ë§ê²Œ ë³´ì—¬ì¤˜\"\n",
        "}\n",
        "response = chain.invoke(query)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eU6NQHptGwg",
        "outputId": "f8fdb736-58c1-4412-ea29-db2340b5387e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- ì •ì±…ì— ëŒ€í•œ ìš”ì•½:\n",
            "  - ê¹€ì§€í›ˆì€ ë¶€ì¥ ì§ê¸‰ìœ¼ë¡œ ì—°ì°¨ íœ´ê°€ëŠ” ê¸°ë³¸ 22ì¼ì´ë©°, ê·¼ì† 10ë…„ ì´ìƒìœ¼ë¡œ +4ì¼ì´ ì¶”ê°€ë˜ì–´ ì´ 26ì¼ì˜ ì—°ì°¨ê°€ ë¶€ì—¬ë©ë‹ˆë‹¤. ë‚¨ì€ ì—°ì°¨ëŠ” ìµœëŒ€ 5ì¼ê¹Œì§€ ì´ì›”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì„±ê³¼ ë“±ê¸‰ BëŠ” ë¶€ì¥ ì§ê¸‰ì— ëŒ€í•´ 3~5%ì˜ ì—°ë´‰ ìƒìŠ¹ë¥ ì„ ì ìš© ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
            "\n",
            "- ê³„ì‚°/ê·œì •ì— ëŒ€í•œ ì ìš©:\n",
            "  - ê¸°ë³¸ ì—°ì°¨: 22ì¼\n",
            "  - ê·¼ì† ê°€ì‚°: 4ì¼ (ê·¼ì† 10ë…„ ì´ìƒ)\n",
            "  - ì´ ì—°ì°¨: 22ì¼ + 4ì¼ = 26ì¼\n",
            "  - ë¯¸ì‚¬ìš© ì—°ì°¨: ë‚¨ì€ ì—°ì°¨ 3ì¼ (ì´ì›” ê°€ëŠ¥ ìµœëŒ€ 5ì¼)\n",
            "\n",
            "- ê²°ë¡ (í•œì¤„): ê¹€ì§€í›ˆì˜ ì„±ê³¼ ë“±ê¸‰ì€ Bì´ë©°, ë‚¨ì€ ì—°ì°¨ëŠ” 3ì¼ì…ë‹ˆë‹¤.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google RSSê¸°ë°˜ ì›¹ê²€ìƒ‰ ì—ì´ì „íŠ¸ ì‘ì„±"
      ],
      "metadata": {
        "id": "v3QSBLq2EhPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q feedparser"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l805H_fhuAiO",
        "outputId": "9e2418f9-2aa4-4d08-a915-94dee04a156f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/81.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m81.5/81.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_core.documents import Document"
      ],
      "metadata": {
        "id": "0IljeT6fE-3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ë‚´ë¶€ ë¬¸ì„œ ìƒì„±\n",
        "documents = [\n",
        "    Document(page_content = \"ìš°ë¦¬íšŒì‚¬ëŠ” 2020ë…„ì— ì„¤ë¦½ëœ AIìŠ¤íƒ€íŠ¸ì—…ì…ë‹ˆë‹¤.\"),\n",
        "    Document(page_content = \"ì£¼ë ¥ ì œí’ˆì€ ê³ ê° ìƒë‹´ ì±—ë´‡ ì†”ë£¨ì…˜ì…ë‹ˆë‹¤.\"),\n",
        "    Document(page_content = \"í˜„ì¬ ì§ì›ìˆ˜ëŠ” 50ëª…ì´ê³ , ì„œìš¸ì— ë³¸ì‚¬ê°€ ìˆìŠµë‹ˆë‹¤.\"),\n",
        "    Document(page_content = \"2024ë…„ë„ ë§¤ì¶œì€ ì „ë…„ëŒ€ë¹„ 150% ì„±ì¥í•˜ê³  ìˆìŠµë‹ˆë‹¤.\"),\n",
        "    Document(page_content = \"ì£¼ìš” ê³ ê°ì‚¬ëŠ” kakao, naver, caupang ë“± ì…ë‹ˆë‹¤.\"),\n",
        "]"
      ],
      "metadata": {
        "id": "9rCuhC8lEjiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ë¬¸ì„œ -> ì„ë² ë”© / chroma db / retrieverê°€ í•„ìš”í•˜ë‹¤!\n",
        "emb = OpenAIEmbeddings()\n",
        "vectorstore = Chroma.from_documents(documents=documents, embedding = emb)\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\" : 2})"
      ],
      "metadata": {
        "id": "rVyMaTQCFZZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.get_relevant_documents(\"ì„¤ë¦½ë…„ì›”\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlMsEPwlGQh-",
        "outputId": "935b9b2e-c16f-4852-dbc3-1fb4d2e982cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={}, page_content='ìš°ë¦¬íšŒì‚¬ëŠ” 2020ë…„ì— ì„¤ë¦½ëœ AIìŠ¤íƒ€íŠ¸ì—…ì…ë‹ˆë‹¤.'),\n",
              " Document(metadata={}, page_content='2024ë…„ë„ ë§¤ì¶œì€ ì „ë…„ëŒ€ë¹„ 150% ì„±ì¥í•˜ê³  ìˆìŠµë‹ˆë‹¤.')]"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import feedparser\n",
        "from urllib.parse import quote\n",
        "rss = f\"https://news.google.com/rss/search?q={quote(\"ì‚¼ì„±ì „ì\")}&hl=ko&gl=KR&ceid=KR:ko\"\n",
        "feed = feedparser.parse(rss)"
      ],
      "metadata": {
        "id": "mEN9PllcKXc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import feedparser\n",
        "from urllib.parse import quote\n",
        "\n",
        "def fetch_google_news(query, max_results = 3):\n",
        "    rss = f\"https://news.google.com/rss/search?q={quote(query)}&hl=ko&gl=KR&ceid=KR:ko\"\n",
        "    feed = feedparser.parse(rss)\n",
        "    lines = []\n",
        "    # title(ì œëª©) / link(ì›ë¬¸) / summary(ìš”ì•½/ë¯¸ë¦¬ë³´ê¸°) / publish(ê³„ì‹œ ì‹œê°) / source(ì›ë³¸ ë§¤ì²´ì •ë³´)\n",
        "    for e in feed.entries[:max_results]:\n",
        "        # ë‰´ìŠ¤ì—ì„œ 4ê°€ì§€ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ê³  -> ë¦¬ìŠ¤íŠ¸ -> join í…ìŠ¤íŠ¸í™”\n",
        "        title = e.get(\"title\",\"\").strip()\n",
        "        link  = e.get(\"link\" ,\"\")\n",
        "        date  = e.get(\"published\", \"ë‚ ì§œ ë¯¸ìƒ\")\n",
        "        # eê°ì²´ì—ì„œ sourceê°€ ìˆìœ¼ë©´ êº¼ë‚´ê³ , ì—†ìœ¼ë©´ None / ìˆìœ¼ë©´ title ì†ì„± ê°€ì ¸ì˜¤ê³  ì—†ìœ¼ë©´ ì¶œì²˜ ë¯¸ìƒ\n",
        "        source = getattr(getattr(e, \"source\", None), \"title\", \"ì¶œì²˜ ë¯¸ìƒ\")\n",
        "        lines.append(f\"{title}\\n  ì¶œì²˜ : {source} | ë‚ ì§œ {date} \\n ë§í¬ {link}\")\n",
        "\n",
        "    return \"\\n\\n\".join(lines)"
      ],
      "metadata": {
        "id": "-X-YSUe6GVz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LCEL íŒŒì´í”„ë¼ì¸ êµ¬í˜„"
      ],
      "metadata": {
        "id": "mSnBfHZORJTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnableLambda, RunnablePassthrough, RunnableParallel\n",
        "\n",
        "# Formatter í¬ë©”í„°\n",
        "\n",
        "# ë‚´ë¶€ë¬¸ì„œ ìš”ì•½ê¸° RAG ê²€ìƒ‰ê²°ê³¼ë¥¼ ë°›ì•„ì„œ page_contentë¥¼ í•œì¤„ì˜ ë¬¸ìì—´ë¡œ í‘œí˜„í•˜ëŠ” êµ¬ë¬¸\n",
        "format_docs = RunnableLambda(lambda docs : \"\\n\".join(d.page_content for d in docs))\n",
        "\n",
        "# ë‰´ìŠ¤ ìˆ˜ì§‘ê¸° -> í—¤ë“œë¼ì¸ 3ê°œì— ëŒ€í•œ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” êµ¬ë¬¸\n",
        "news_tool   = RunnableLambda(lambda q: fetch_google_news(q, max_results = 3))\n",
        "\n",
        "# ë³‘ë ¬ ì‹¤í–‰ -> í”„ë¡¬í”„íŠ¸ì•ˆì— ë“¤ì–´ê°€ì„œ LLMì´ ë‹µë³€í•  ìˆ˜ ìˆê²Œ êµ¬ì¡°ë¥¼ ë§Œë“¤ì–´ì•¼ í•¨\n",
        "gather = RunnableParallel(\n",
        "    internal = retriever | format_docs, # ë‚´ë¶€ ë¬¸ì„œ\n",
        "    news = news_tool, # ë‰´ìŠ¤\n",
        "    q = RunnablePassthrough() # ì›ë˜ ì§ˆë¬¸ì„ ê·¸ëŒ€ë¡œ ì „ë‹¬\n",
        ")\n",
        "\n",
        "# ë³‘ë ¬ ì‹¤í–‰ ì˜ˆì‹œ ì‚¼ì„±ì „ì\n",
        "# internal : ì‚¬ë‚´ ì „ëµ ë¬¸ì„œ ë‚´ìš© ìš”ì•½\n",
        "# news : ì˜¤ëŠ˜ì í—¤ë“œë¼ì¸ ë‰´ìŠ¤ 3ê°œ\n",
        "# q : ì§ˆë¬¸ ê·¸ëŒ€ë¡œ\n"
      ],
      "metadata": {
        "id": "7Uv4qOemLqS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "ì•„ë˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.\n",
        "\n",
        "[ë‚´ë¶€ìë£Œ]\n",
        "{internal}\n",
        "\n",
        "[ë‰´ìŠ¤]\n",
        "{news}\n",
        "\n",
        "ì§ˆë¬¸ : {q}\n",
        "\n",
        "ê·œì¹™ :\n",
        "- ì¶œì²˜ë¥¼ ëª…í™•íˆ êµ¬ë¶„í•´ì„œ í‘œê¸°([ë‚´ë¶€ìë£Œ]/[ë‰´ìŠ¤] ì¤‘ì—ì„œ)\n",
        "- ë‚ ì§œ, ìˆ«ìëŠ” ì •í™•í•˜ê²Œ ì¸ìš©\n",
        "- ì •ë³´ê°€ ë¶€ì¡±í•˜ê±°ë‚˜ ì—†ìœ¼ë©´ \"ì¶”ê°€ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤.\"ë¼ê³  í•œ ë¬¸ì¥ìœ¼ë¡œ ëª…ì‹œí•´ë¼\n",
        "- í•œêµ­ì–´ë¡œ 5ë¬¸ì¥ ì´ë‚´ë¡œ ì‘ì„±í•´ë¼\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "FzjVR481R1WA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model = 'gpt-4o-mini', temperature = 0)\n",
        "chain = gather | prompt | llm"
      ],
      "metadata": {
        "id": "fPybG9tlUMgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [\n",
        "    'ìš°ë¦¬ íšŒì‚¬ í˜„ì¬ ì§ì›ìˆ˜ëŠ”?',\n",
        "    'ì‚¼ì„±ì „ì ìµœì‹  ë‰´ìŠ¤ë¥¼ ì•Œë ¤ì¤˜',\n",
        "    '2025ë…„ 10ì›” ì• í”Œ ì‹¤ì  ë°œí‘œ ì†Œì‹',\n",
        "    'ìš°ë¦¬ íšŒì‚¬ì™€ ìœ ì‚¬í•œ 2025ë…„ 10ì›” ê¸°ì¤€ AI íšŒì‚¬ ë™í–¥'\n",
        "]\n",
        "\n",
        "for q in questions:\n",
        "    print(q)\n",
        "    print(chain.invoke(q).content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3LCWeFeUW5b",
        "outputId": "4bd91ad2-41d5-4387-b3f4-c499d09b253e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ìš°ë¦¬ íšŒì‚¬ í˜„ì¬ ì§ì›ìˆ˜ëŠ”?\n",
            "ìš°ë¦¬ íšŒì‚¬ì˜ í˜„ì¬ ì§ì›ìˆ˜ëŠ” 50ëª…ì…ë‹ˆë‹¤. ì´ ì •ë³´ëŠ” ë‚´ë¶€ìë£Œì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íšŒì‚¬ëŠ” 2020ë…„ì— ì„¤ë¦½ëœ AI ìŠ¤íƒ€íŠ¸ì—…ìœ¼ë¡œ, ì„œìš¸ì— ë³¸ì‚¬ë¥¼ ë‘ê³  ìˆìŠµë‹ˆë‹¤. ì¶”ê°€ì ì¸ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n",
            "ì‚¼ì„±ì „ì ìµœì‹  ë‰´ìŠ¤ë¥¼ ì•Œë ¤ì¤˜\n",
            "ì‚¼ì„±ì „ìëŠ” 2025ë…„í˜• ë¹„ìŠ¤í¬í¬ AI ì„¸íƒê¸°ì™€ ê±´ì¡°ê¸°ë¥¼ ì¶œì‹œí–ˆìŠµë‹ˆë‹¤. ì´ ì œí’ˆì€ ìµœì‹  ê¸°ìˆ ì„ ì ìš©í•˜ì—¬ ì†Œë¹„ìë“¤ì—ê²Œ ë” ë‚˜ì€ ì‚¬ìš© ê²½í—˜ì„ ì œê³µí•  ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë©ë‹ˆë‹¤. ë˜í•œ, ì‚¼ì„±ì „ìëŠ” 'ë°˜ë„ì²´ ì¶”ê²©ì'ë¡œì„œ 2027ë…„ ëŒ€ë°˜ì „ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì œì‹œí•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ì™€ ê´€ë ¨ëœ ìì„¸í•œ ë‚´ìš©ì€ ì¤‘ì•™ì¼ë³´ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¶”ê°€ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n",
            "2025ë…„ 10ì›” ì• í”Œ ì‹¤ì  ë°œí‘œ ì†Œì‹\n",
            "2025ë…„ 10ì›” ì• í”Œì˜ ì‹¤ì  ë°œí‘œ ì†Œì‹ì´ ì—¬ëŸ¬ ë§¤ì²´ì—ì„œ ë³´ë„ë˜ì—ˆìŠµë‹ˆë‹¤. [ë‰´ìŠ¤]ì— ë”°ë¥´ë©´, ì• í”Œì€ ì•„ì´í°17ë¡œ ì‚¬ìƒ ìµœëŒ€ ì‹¤ì ì„ ê¸°ë¡í•  ê²ƒìœ¼ë¡œ ì „ë§í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë˜í•œ, [ë‰´ìŠ¤]ì—ì„œëŠ” ì• í”Œì´ ì‹¤ì‹œê°„ ë²ˆì—­ ê¸°ëŠ¥ì„ AirPods ë° ì „í™”, FaceTimeì—ì„œ í•œêµ­ì–´, ì¤‘êµ­ì–´, ì¼ë³¸ì–´ë¡œ ì§€ì›í•œë‹¤ê³  ì „í–ˆìŠµë‹ˆë‹¤. êµ¬ì²´ì ì¸ ì‹¤ì  ìˆ˜ì¹˜ë‚˜ ì„¸ë¶€ ì‚¬í•­ì€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì¶”ê°€ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n",
            "ìš°ë¦¬ íšŒì‚¬ì™€ ìœ ì‚¬í•œ 2025ë…„ 10ì›” ê¸°ì¤€ AI íšŒì‚¬ ë™í–¥\n",
            "2025ë…„ 10ì›” ê¸°ì¤€ AI íšŒì‚¬ ë™í–¥ì— ëŒ€í•œ ì •ë³´ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. AI ìŠ¤íƒ€íŠ¸ì—…ì¸ ìš°ë¦¬ íšŒì‚¬ëŠ” 2024ë…„ë„ ë§¤ì¶œì´ ì „ë…„ ëŒ€ë¹„ 150% ì„±ì¥í•˜ê³  ìˆìŠµë‹ˆë‹¤([ë‚´ë¶€ìë£Œ]). ë˜í•œ, AI ê´€ë ¨ ë‰´ìŠ¤ì—ì„œëŠ” Metaì— Thinking Machines Lab ê³µë™ ì°½ë¦½ìê°€ í•©ë¥˜í•˜ê³ , OpenAIì˜ GPT-5ê°€ ì •ì¹˜ì  í¸ê²¬ì„ 30% ì¤„ì´ëŠ” ë“±ì˜ í˜ì‹ ì ì¸ ë°œì „ì´ ë³´ë„ë˜ì—ˆìŠµë‹ˆë‹¤([ë‰´ìŠ¤]). ê·¸ëŸ¬ë‚˜ 2025ë…„ AI ì‹œì¥ì˜ ì „ë°˜ì ì¸ ë™í–¥ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì •ë³´ëŠ” ë¶€ì¡±í•©ë‹ˆë‹¤. ì¶”ê°€ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hybrid Search êµ¬í˜„"
      ],
      "metadata": {
        "id": "qF82AZR8e7F3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rank_bm25 pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2j-Ez7rVD3O",
        "outputId": "10539370-abc9-4753-d671-67934a54a199"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rank_bm25 in /usr/local/lib/python3.12/dist-packages (0.2.2)\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-6.1.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rank_bm25) (2.0.2)\n",
            "Downloading pypdf-6.1.3-py3-none-any.whl (323 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m323.9/323.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-6.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import Chroma"
      ],
      "metadata": {
        "id": "aVb-nIkbfDVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. ë¬¸ì„œë¡œë“œ\n",
        "loader = PyPDFLoader('/content/R2510425.pdf')\n",
        "pages = loader.load()"
      ],
      "metadata": {
        "id": "J3YJ2l4Ifb1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. ë¬¸ì„œë¶„í• \n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size = 800, chunk_overlap = 200)\n",
        "docs = splitter.split_documents(pages)"
      ],
      "metadata": {
        "id": "5_cjibUnfjav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. ë°±í„°DBêµ¬ì¶•\n",
        "embedding = OpenAIEmbeddings(model = 'text-embedding-3-small')\n",
        "db = Chroma.from_documents(docs, embedding, persist_directory=\"./policy_vector_db\")\n",
        "db.persist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wTPrj8Tf-1_",
        "outputId": "e56353ab-f1f6-411d-afb1-67fa0cbd9cb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4165476361.py:4: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
            "  db.persist()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. BM25 + Vectorê¸°ë°˜ ê²€ìƒ‰ê¸°ë¥¼ ìƒì„±"
      ],
      "metadata": {
        "id": "6puKjp7LgtYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.retrievers import BM25Retriever\n",
        "from langchain.retrievers import EnsembleRetriever\n",
        "\n",
        "# BM25 í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰\n",
        "bm25 = BM25Retriever.from_documents(docs)\n",
        "\n",
        "# Vector ê¸°ë°˜ ê²€ìƒ‰\n",
        "vector = db.as_retriever(search_kwargs = {\"k\" : 3})\n",
        "\n",
        "# Hybrid (ì•™ìƒë¸” ê¸°ë°˜ ê²€ìƒ‰ í‚¤ì›Œë“œ 5: ë²¡í„° 5)\n",
        "hybrid = EnsembleRetriever(\n",
        "    retrievers = [bm25, vector],\n",
        "    weights = [0.5, 0.5]\n",
        ")"
      ],
      "metadata": {
        "id": "pPX_pL47gQ2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"ìˆ˜ë„ê¶Œã†ê·œì œì§€ì—­ì˜ ì£¼ë‹´ëŒ€ í•œë„ëŠ”?\"\n",
        "\n",
        "print(\"ğŸ”¹ BM25 ê²°ê³¼:\")\n",
        "for d in bm25.get_relevant_documents(query)[:2]:\n",
        "    print(\"-\", d.page_content[:120], \"...\\n\")\n",
        "\n",
        "print(\"\\nğŸ”¹ Vector ê²°ê³¼:\")\n",
        "for d in vector.get_relevant_documents(query)[:2]:\n",
        "    print(\"-\", d.page_content[:120], \"...\\n\")\n",
        "\n",
        "print(\"\\nğŸ”¹ Hybrid ê²°ê³¼:\")\n",
        "for d in hybrid.get_relevant_documents(query)[:2]:\n",
        "    print(\"-\", d.page_content[:120], \"...\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jy7wxdC7hDSB",
        "outputId": "a218d807-79d5-4a7c-9a76-a3a60de1325e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ”¹ BM25 ê²°ê³¼:\n",
            "- - ì¡°ì •ëŒ€ìƒì§€ì—­ ë° íˆ¬ê¸°ê³¼ì—´ì§€êµ¬ëŠ” ê¸°ì¡´ì— ì§€ì •ë˜ì–´ ìˆëŠ” ê°•ë‚¨êµ¬, ì„œì´ˆêµ¬, ì†¡íŒŒêµ¬, ìš©ì‚°êµ¬ 4ê°œ ìì¹˜êµ¬ì— ëŒ€í•´ ì§€ì •ì„ ìœ ì§€í•˜ê³ , ê·¸ ì™¸ ì„œìš¸ 21ê°œ ìì¹˜êµ¬ ì „ì²´ì™€ ê²½ê¸°ë„ 12ê°œ ì§€ì—­*ì€ ì‹ ê·œ ì§€ì •í•œë‹¤.    * ê³¼ì²œì‹œ ...\n",
            "\n",
            "- - ìˆ˜ë„ê¶Œ ë° ê·œì œì§€ì—­ ë‚´ ì£¼ë‹´ëŒ€ì— í•œí•´ ìŠ¤íŠ¸ë ˆìŠ¤ ê¸ˆë¦¬ë¥¼ 1.5%ì—ì„œ 3.0%ë¡œ ìƒí–¥ ì¡°ì •í•œë‹¤.  - 1ì£¼íƒì(ì†Œìœ ì£¼íƒì˜ ì§€ì—­ì€ ë¬´ê´€)ê°€ ìˆ˜ë„ê¶Œã†ê·œì œì§€ì—­ì—ì„œ ì„ì°¨ì¸ìœ¼ë¡œì„œ ì „ì„¸ëŒ€ì¶œì„ ë°›ëŠ” ê²½ìš° ì „ì„¸ëŒ€ì¶œì˜ ì´ììƒí™˜ë¶„ì„  ...\n",
            "\n",
            "\n",
            "ğŸ”¹ Vector ê²°ê³¼:\n",
            "- - ì¡°ì •ëŒ€ìƒì§€ì—­ ë° íˆ¬ê¸°ê³¼ì—´ì§€êµ¬ëŠ” ê¸°ì¡´ì— ì§€ì •ë˜ì–´ ìˆëŠ” ê°•ë‚¨êµ¬, ì„œì´ˆêµ¬, ì†¡íŒŒêµ¬, ìš©ì‚°êµ¬ 4ê°œ ìì¹˜êµ¬ì— ëŒ€í•´ ì§€ì •ì„ ìœ ì§€í•˜ê³ , ê·¸ ì™¸ ì„œìš¸ 21ê°œ ìì¹˜êµ¬ ì „ì²´ì™€ ê²½ê¸°ë„ 12ê°œ ì§€ì—­*ì€ ì‹ ê·œ ì§€ì •í•œë‹¤.    * ê³¼ì²œì‹œ ...\n",
            "\n",
            "- - ì¡°ì •ëŒ€ìƒì§€ì—­ ë° íˆ¬ê¸°ê³¼ì—´ì§€êµ¬ëŠ” ê¸°ì¡´ì— ì§€ì •ë˜ì–´ ìˆëŠ” ê°•ë‚¨êµ¬, ì„œì´ˆêµ¬, ì†¡íŒŒêµ¬, ìš©ì‚°êµ¬ 4ê°œ ìì¹˜êµ¬ì— ëŒ€í•´ ì§€ì •ì„ ìœ ì§€í•˜ê³ , ê·¸ ì™¸ ì„œìš¸ 21ê°œ ìì¹˜êµ¬ ì „ì²´ì™€ ê²½ê¸°ë„ 12ê°œ ì§€ì—­*ì€ ì‹ ê·œ ì§€ì •í•œë‹¤.    * ê³¼ì²œì‹œ ...\n",
            "\n",
            "\n",
            "ğŸ”¹ Hybrid ê²°ê³¼:\n",
            "- - ì¡°ì •ëŒ€ìƒì§€ì—­ ë° íˆ¬ê¸°ê³¼ì—´ì§€êµ¬ëŠ” ê¸°ì¡´ì— ì§€ì •ë˜ì–´ ìˆëŠ” ê°•ë‚¨êµ¬, ì„œì´ˆêµ¬, ì†¡íŒŒêµ¬, ìš©ì‚°êµ¬ 4ê°œ ìì¹˜êµ¬ì— ëŒ€í•´ ì§€ì •ì„ ìœ ì§€í•˜ê³ , ê·¸ ì™¸ ì„œìš¸ 21ê°œ ìì¹˜êµ¬ ì „ì²´ì™€ ê²½ê¸°ë„ 12ê°œ ì§€ì—­*ì€ ì‹ ê·œ ì§€ì •í•œë‹¤.    * ê³¼ì²œì‹œ ...\n",
            "\n",
            "- - ìˆ˜ë„ê¶Œ ë° ê·œì œì§€ì—­ ë‚´ ì£¼ë‹´ëŒ€ì— í•œí•´ ìŠ¤íŠ¸ë ˆìŠ¤ ê¸ˆë¦¬ë¥¼ 1.5%ì—ì„œ 3.0%ë¡œ ìƒí–¥ ì¡°ì •í•œë‹¤.  - 1ì£¼íƒì(ì†Œìœ ì£¼íƒì˜ ì§€ì—­ì€ ë¬´ê´€)ê°€ ìˆ˜ë„ê¶Œã†ê·œì œì§€ì—­ì—ì„œ ì„ì°¨ì¸ìœ¼ë¡œì„œ ì „ì„¸ëŒ€ì¶œì„ ë°›ëŠ” ê²½ìš° ì „ì„¸ëŒ€ì¶œì˜ ì´ììƒí™˜ë¶„ì„  ...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# reranker êµ¬í˜„"
      ],
      "metadata": {
        "id": "IyNgw4zHjBh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
        "\n",
        "# 1. ëª¨ë¸ ì •ì˜\n",
        "llm = ChatOpenAI(model = 'gpt-4o-mini', temperature = 0)\n",
        "\n",
        "# 2. í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
        "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "ì•„ë˜ ë¬¸ì„œ ì¡°ê°ë“¤ì„ ì½ê³ , ì§ˆë¬¸ê³¼ ê´€ë ¨ì„±ì— ë”°ë¼ì„œ ìˆœì„œë¥¼ ì •ë ¬í•˜ì„¸ìš”.\n",
        "ì§ˆë¬¸ : {query}\n",
        "ë¬¸ì„œ : {docs}\n",
        "\n",
        "ì¶œë ¥ : ê´€ë ¨ì„±ì´ ë†’ì€ ìˆœì„œëŒ€ë¡œ ë²ˆí˜¸ë§Œ ë‚˜ì—´í•˜ì„¸ìš”.\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "WdCCBfE7h_sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Reranker ì²´ì¸ (LCEL ì²´ì¸)\n",
        "# iê°€ ìˆœì„œëŒ€ë¡œ ê·¸ëŒ€ë¡œë‚˜ì˜¤ê²Œ ë˜ë©´ ë¦¬íŠ¸ë¦¬ë²„ê°€ ì˜ ë™ì‘í–ˆë‹¤.\n",
        "# iì˜ ìˆœì„œê°€ ë³€ê²½ì´ë˜ì—ˆë‹¤ -> ë­”ê°€ ë¬¸ì œê°€ ìˆê±°ë‚˜ ì¡°ì •ì´ í•„ìš”\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(f\" {i}, {d.page_content[:250]}\" for i, d in enumerate(docs))"
      ],
      "metadata": {
        "id": "xMSEpovjkA1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reranker = (\n",
        "    {\n",
        "        \"query\" : RunnablePassthrough(),\n",
        "        \"docs\" : RunnableLambda(lambda q: format_docs(hybrid.get_relevant_documents(q)))\n",
        "    }\n",
        "    | prompt\n",
        "    | llm\n",
        ")"
      ],
      "metadata": {
        "id": "zVJxHzuNjuOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"ëŒ€ì¶œì€ ì–´ë–»ê²Œ ë°›ì•„ì•¼ë˜\"\n",
        "print(reranker.invoke(query).content)\n",
        "\n",
        "# AIê°€ ë‹µë³€í•œ ë¬¸ì¥ë“¤ì€ ëª¨ë¸ì´ íŠ¹ë³„íˆ ìˆœìœ„ë¥¼ êµ¬ë³„í•  í•„ìš”ê°€ ì—†ë‹¤! -> ëª¨ë‘ ë¹„ìŠ·í•˜ê±°ë‚˜ êµ¬ë¶„í•˜ê¸°ì—ëŠ” ë¶ˆë¶„ëª…í•˜ë‹¤\n",
        "# -> ìˆœì„œê·¸ëŒ€ë¡œ ì¶”ì²œí•´ë„ëœë‹¤."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xf7SoVUVlPUA",
        "outputId": "b2be129a-0282-465e-85d1-62b46e874ac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2, 3, 0, 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HhVYvWrvlY0r"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}